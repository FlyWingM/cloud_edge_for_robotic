{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fff6b3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:LocalDebug:Model expects UINT8 input, converting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ObjectDetector with model_path=./od_models/model_cube.tflite\n",
      "Loading TensorFlow Lite model, _load_model, from: ./od_models/model_cube.tflite\n",
      "TFLite Model Input Details:\n",
      "{'name': 'serving_default_images:0', 'index': 0, 'shape': array([  1, 320, 320,   3]), 'shape_signature': array([  1, 320, 320,   3]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0078125, 127), 'quantization_parameters': {'scales': array([0.0078125], dtype=float32), 'zero_points': array([127]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "\n",
      "TFLite Model Output Details:\n",
      "{'name': 'StatefulPartitionedCall:1', 'index': 600, 'shape': array([ 1, 25]), 'shape_signature': array([ 1, 25]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:3', 'index': 598, 'shape': array([ 1, 25,  4]), 'shape_signature': array([ 1, 25,  4]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 601, 'shape': array([1]), 'shape_signature': array([1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:2', 'index': 599, 'shape': array([ 1, 25]), 'shape_signature': array([ 1, 25]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "TFLite model loaded successfully.\n",
      "Resizing image from (480, 640) to (320, 320)\n",
      "Output 0: Name=StatefulPartitionedCall:1, Shape=[ 1 25], Type=<class 'numpy.float32'>\n",
      "Output 1: Name=StatefulPartitionedCall:3, Shape=[ 1 25  4], Type=<class 'numpy.float32'>\n",
      "Output 2: Name=StatefulPartitionedCall:0, Shape=[1], Type=<class 'numpy.float32'>\n",
      "Output 3: Name=StatefulPartitionedCall:2, Shape=[ 1 25], Type=<class 'numpy.float32'>\n",
      "Inference Output: {'class_ids': [0.55859375, 0.42578125, 0.1484375, 0.046875, 0.0390625, 0.0390625, 0.0390625, 0.03125, 0.03125, 0.03125, 0.03125, 0.02734375, 0.02734375, 0.02734375, 0.02734375, 0.02734375, 0.02734375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375], 'scores': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0], 'bboxes': [[0.7034383416175842, 0.554363489151001, 0.8278552889823914, 0.6643427610397339], [-0.0480169951915741, -0.005758374929428101, 0.9473190307617188, 0.9721924066543579], [0.094544418156147, 0.5781492590904236, 0.20947682857513428, 0.6779699921607971], [0.42059338092803955, 0.536848247051239, 0.5355257987976074, 0.6402495503425598], [0.08865635097026825, 0.818085789680481, 0.3907138705253601, 0.9899567365646362], [0.03291177749633789, -0.07800590246915817, 0.658696711063385, 0.2367464005947113], [0.151505708694458, -0.08941650390625, 1.4837639331817627, 0.9638279676437378], [0.27934861183166504, 0.06508907675743103, 1.0677882432937622, 0.8397573232650757], [-0.30346351861953735, -0.585830807685852, 0.6524953842163086, 0.8563698530197144], [-0.5146918296813965, -0.11834609508514404, 0.7293514013290405, 1.118346095085144], [-0.154680073261261, 0.14114588499069214, 1.2212834358215332, 1.3257105350494385], [0.18527396023273468, 0.8342296481132507, 0.3669983744621277, 0.949161946773529], [0.0686681866645813, 0.8760080337524414, 0.35265955328941345, 1.0572090148925781], [0.6217001676559448, 0.8264275193214417, 0.839513897895813, 0.9422624707221985], [0.3148067891597748, -0.03606782853603363, 0.8928866386413574, 0.28711479902267456], [0.7371211051940918, 0.41475987434387207, 1.0301626920700073, 0.681502103805542], [0.0988282561302185, 0.038678765296936035, 0.8271633386611938, 0.6881927847862244], [0.6003547310829163, -0.02013178914785385, 0.9244707226753235, 0.14145952463150024], [0.20675601065158844, 0.028665393590927124, 0.48853445053100586, 0.3727470636367798], [0.11553338170051575, -0.02358143776655197, 0.631562352180481, 0.16596755385398865], [0.45835214853286743, 0.2161390483379364, 0.8939797282218933, 0.5100269317626953], [0.7094374895095825, 0.31450098752975464, 1.0129904747009277, 0.574285089969635], [0.6082071661949158, 0.11067140102386475, 1.0205886363983154, 0.623185396194458], [-0.7466318607330322, 0.23030078411102295, 0.7635018825531006, 1.45614492893219], [0.22681665420532227, -0.6266010999679565, 1.141577124595642, 0.8029488325119019]]}\n",
      "[Cube Model] Detections above threshold 0.5: 19\n",
      "Detections: [{'label': 0, 'confidence': 1.0, 'bbox': (0.094544418156147, 0.5781492590904236, 0.11493241041898727, 0.09982073307037354)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.42059338092803955, 0.536848247051239, 0.11493241786956787, 0.1034013032913208)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.08865635097026825, 0.818085789680481, 0.30205751955509186, 0.17187094688415527)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.03291177749633789, -0.07800590246915817, 0.6257849335670471, 0.3147523030638695)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.151505708694458, -0.08941650390625, 1.3322582244873047, 1.0532444715499878)}, {'label': 0, 'confidence': 1.0, 'bbox': (-0.30346351861953735, -0.585830807685852, 0.955958902835846, 1.4422006607055664)}, {'label': 0, 'confidence': 2.0, 'bbox': (-0.5146918296813965, -0.11834609508514404, 1.244043231010437, 1.236692190170288)}, {'label': 0, 'confidence': 1.0, 'bbox': (-0.154680073261261, 0.14114588499069214, 1.3759635090827942, 1.1845646500587463)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.18527396023273468, 0.8342296481132507, 0.181724414229393, 0.11493229866027832)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.0686681866645813, 0.8760080337524414, 0.28399136662483215, 0.18120098114013672)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.3148067891597748, -0.03606782853603363, 0.5780798494815826, 0.3231826275587082)}, {'label': 0, 'confidence': 2.0, 'bbox': (0.7371211051940918, 0.41475987434387207, 0.2930415868759155, 0.2667422294616699)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.6003547310829163, -0.02013178914785385, 0.3241159915924072, 0.1615913137793541)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.20675601065158844, 0.028665393590927124, 0.2817784398794174, 0.34408167004585266)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.11553338170051575, -0.02358143776655197, 0.5160289704799652, 0.18954899162054062)}, {'label': 0, 'confidence': 2.0, 'bbox': (0.7094374895095825, 0.31450098752975464, 0.3035529851913452, 0.25978410243988037)}, {'label': 0, 'confidence': 2.0, 'bbox': (0.6082071661949158, 0.11067140102386475, 0.41238147020339966, 0.5125139951705933)}, {'label': 0, 'confidence': 1.0, 'bbox': (-0.7466318607330322, 0.23030078411102295, 1.5101337432861328, 1.225844144821167)}, {'label': 0, 'confidence': 1.0, 'bbox': (0.22681665420532227, -0.6266010999679565, 0.9147604703903198, 1.4295499324798584)}]\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell:\n",
    "from services.microservice_od_offline import load_detector, detect_on_image\n",
    "\n",
    "# Load your preferred quality: llow, medium high\n",
    "detector = load_detector(model_quality=\"llow\", confidence_threshold=0.5)\n",
    "\n",
    "# Run detection on a local image\n",
    "results = detect_on_image(detector, \"images/14.jpg\")\n",
    "print(\"Detections:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da786b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
